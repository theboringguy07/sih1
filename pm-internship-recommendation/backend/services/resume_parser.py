import PyPDF2
import docx
import re
from io import BytesIO
from .indic_text_processor import IndicTextProcessor
from .translation_service import TranslationService

# Optional dependencies for better functionality
try:
    from pdf2image import convert_from_bytes
    import pytesseract
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False
    print("WARNING: OCR dependencies not available. Install pillow and pytesseract for better PDF parsing.")

try:
    import spacy
    SPACY_AVAILABLE = True
except ImportError:
    SPACY_AVAILABLE = False
    print("WARNING: spaCy not available. Name extraction will use fallback method.")


class ResumeParser:
    def __init__(self):
        # Initialize multilingual text processing
        self.text_processor = IndicTextProcessor()
        self.translation_service = TranslationService()
        
        # Load spaCy model if available
        self.nlp = None
        if SPACY_AVAILABLE: 
            try:
                self.nlp = spacy.load("en_core_web_sm")
            except OSError:
                print("WARNING: spaCy model 'en_core_web_sm' not found.")
                print("    For better name extraction, install with: python -m spacy download en_core_web_sm")
                self.nlp = None

        # Multilingual skills dictionary (extendable)
        self.skills_keywords = {
            'en': [
                'python', 'java', 'javascript', 'html', 'css', 'react', 'angular', 'vue',
                'node.js', 'express', 'django', 'flask', 'spring', 'sql', 'mysql', 'postgresql',
                'mongodb', 'git', 'docker', 'kubernetes', 'aws', 'azure', 'gcp', 'linux',
                'windows', 'photoshop', 'illustrator', 'figma', 'sketch', 'autocad', 'solidworks',
                'excel', 'powerpoint', 'word', 'tableau', 'power bi', 'r', 'matlab', 'tensorflow',
                'pytorch', 'machine learning', 'deep learning', 'data science', 'analytics',
                'marketing', 'seo', 'content writing', 'social media', 'communication',
                'leadership', 'project management', 'agile', 'scrum', 'teamwork', 'problem solving'
            ],
            'hi': [
                '‡§™‡§æ‡§Ø‡§•‡§®', '‡§ú‡§æ‡§µ‡§æ', '‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ‡§ø‡§Ç‡§ó', '‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§∞', '‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞', '‡§°‡•á‡§ü‡§æ',
                '‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó', '‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ', '‡§µ‡•á‡§¨ ‡§°‡•á‡§µ‡§≤‡§™‡§Æ‡•á‡§Ç‡§ü', '‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤',
                '‡§°‡§ø‡§ú‡§æ‡§á‡§®', '‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü‡§ø‡§Ç‡§ó', '‡§¨‡§ø‡§ï‡•ç‡§∞‡•Ä', '‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®', '‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ', '‡§∏‡§Ç‡§ö‡§æ‡§∞',
                '‡§ü‡•Ä‡§Æ‡§µ‡§∞‡•ç‡§ï', '‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§®', '‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£', '‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü‡§ø‡§Ç‡§ó'
            ],
            'te': [
                '‡∞™‡±ç‡∞∞‡±ã‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞ø‡∞Ç‡∞ó‡±ç', '‡∞ï‡∞Ç‡∞™‡±ç‡∞Ø‡±Ç‡∞ü‡∞∞‡±ç', '‡∞∏‡∞æ‡∞´‡±ç‡∞ü‡±ç‚Äå‡∞µ‡±á‡∞∞‡±ç', '‡∞°‡±á‡∞ü‡∞æ', '‡∞µ‡±Ü‡∞¨‡±ç ‡∞°‡±Ü‡∞µ‡∞≤‡∞™‡±ç‚Äå‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç',
                '‡∞Æ‡±ä‡∞¨‡±à‡∞≤‡±ç', '‡∞°‡∞ø‡∞ú‡±à‡∞®‡±ç', '‡∞Æ‡∞æ‡∞∞‡±ç‡∞ï‡±Ü‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç', '‡∞∏‡±á‡∞≤‡±ç‡∞∏‡±ç', '‡∞Æ‡±á‡∞®‡±á‡∞ú‡±ç‚Äå‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç',
                '‡∞≤‡±Ä‡∞°‡∞∞‡±ç‚Äå‡∞∑‡∞ø‡∞™‡±ç', '‡∞ï‡∞Æ‡±ç‡∞Ø‡±Ç‡∞®‡∞ø‡∞ï‡±á‡∞∑‡∞®‡±ç', '‡∞ü‡±Ä‡∞Æ‡±ç‚Äå‡∞µ‡∞∞‡±ç‡∞ï‡±ç', '‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç'
            ],
            'ta': [
                '‡Æ®‡Æø‡Æ∞‡Æ≤‡Ææ‡Æï‡Øç‡Æï‡ÆÆ‡Øç', '‡Æï‡Æ£‡Æø‡Æ©‡Æø', '‡ÆÆ‡ØÜ‡Æ©‡Øç‡Æ™‡Øä‡Æ∞‡ØÅ‡Æ≥‡Øç', '‡Æ§‡Æ∞‡Æµ‡ØÅ', '‡Æµ‡Æ≤‡Øà ‡ÆÆ‡Øá‡ÆÆ‡Øç‡Æ™‡Ææ‡Æü‡ØÅ',
                '‡ÆÆ‡Øä‡Æ™‡Øà‡Æ≤‡Øç', '‡Æµ‡Æü‡Æø‡Æµ‡ÆÆ‡Øà‡Æ™‡Øç‡Æ™‡ØÅ', '‡Æö‡Æ®‡Øç‡Æ§‡Øà‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡Æ≤‡Øç', '‡Æµ‡Æø‡Æ±‡Øç‡Æ™‡Æ©‡Øà', '‡ÆÆ‡Øá‡Æ≤‡Ææ‡Æ£‡Øç‡ÆÆ‡Øà',
                '‡Æ§‡Æ≤‡Øà‡ÆÆ‡Øà‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ‡ÆÆ‡Øç', '‡Æ§‡Æï‡Æµ‡Æ≤‡Øç‡Æ§‡Øä‡Æü‡Æ∞‡Øç‡Æ™‡ØÅ', '‡Æï‡ØÅ‡Æ¥‡ØÅ ‡Æµ‡Øá‡Æ≤‡Øà', '‡Æö‡Æø‡Æï‡Øç‡Æï‡Æ≤‡Øç ‡Æ§‡ØÄ‡Æ∞‡Øç‡Æµ‡ØÅ'
            ],
            'bn': [
                '‡¶™‡ßç‡¶∞‡ßã‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ‡¶ø‡¶Ç', '‡¶ï‡¶Æ‡ßç‡¶™‡¶ø‡¶â‡¶ü‡¶æ‡¶∞', '‡¶∏‡¶´‡¶ü‡¶ì‡¶Ø‡¶º‡ßç‡¶Ø‡¶æ‡¶∞', '‡¶°‡¶æ‡¶ü‡¶æ', '‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶°‡ßá‡¶≠‡ßá‡¶≤‡¶™‡¶Æ‡ßá‡¶®‡ßç‡¶ü',
                '‡¶Æ‡ßã‡¶¨‡¶æ‡¶á‡¶≤', '‡¶°‡¶ø‡¶ú‡¶æ‡¶á‡¶®', '‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï‡ßá‡¶ü‡¶ø‡¶Ç', '‡¶∏‡ßá‡¶≤‡¶∏', '‡¶Æ‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶ú‡¶Æ‡ßá‡¶®‡ßç‡¶ü',
                '‡¶≤‡¶ø‡¶°‡¶æ‡¶∞‡¶∂‡¶ø‡¶™', '‡¶ï‡¶Æ‡¶ø‡¶â‡¶®‡¶ø‡¶ï‡ßá‡¶∂‡¶®', '‡¶ü‡¶ø‡¶Æ‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶ï', '‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®'
            ]
        }

        # Education patterns (multilingual)
        self.education_patterns = {
            'en': [
                r'b\.?tech|bachelor.*technology|engineering',
                r'b\.?sc|bachelor.*science',
                r'b\.?com|bachelor.*commerce',
                r'b\.?a|bachelor.*arts',
                r'm\.?tech|master.*technology',
                r'm\.?sc|master.*science',
                r'mba|master.*business',
                r'diploma|polytechnic',
                r'12th|class.*12|higher.*secondary|intermediate',
                r'10th|class.*10|matriculation|secondary'
            ],
            'hi': [
                r'‡§¨‡•Ä\.?‡§ü‡•á‡§ï|‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞‡§ø‡§Ç‡§ó|‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä',
                r'‡§¨‡•Ä\.?‡§è‡§∏‡§∏‡•Ä|‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§®',
                r'‡§¨‡•Ä\.?‡§ï‡•â‡§Æ|‡§µ‡§æ‡§£‡§ø‡§ú‡•ç‡§Ø',
                r'‡§¨‡•Ä\.?‡§è|‡§ï‡§≤‡§æ',
                r'‡§è‡§Æ\.?‡§ü‡•á‡§ï|‡§™‡•ç‡§∞‡•å‡§¶‡•ç‡§Ø‡•ã‡§ó‡§ø‡§ï‡•Ä',
                r'‡§è‡§Æ\.?‡§è‡§∏‡§∏‡•Ä|‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§®',
                r'‡§è‡§Æ‡§¨‡•Ä‡§è|‡§¨‡§ø‡§ú‡§®‡•á‡§∏|‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞',
                r'‡§°‡§ø‡§™‡•ç‡§≤‡•ã‡§Æ‡§æ|‡§™‡•â‡§≤‡§ø‡§ü‡•á‡§ï‡•ç‡§®‡§ø‡§ï',
                r'12‡§µ‡•Ä‡§Ç|‡§ï‡§ï‡•ç‡§∑‡§æ.*12|‡§â‡§ö‡•ç‡§ö ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ‡§ø‡§ï|‡§á‡§Ç‡§ü‡§∞‡§Æ‡•Ä‡§°‡§ø‡§è‡§ü',
                r'10‡§µ‡•Ä‡§Ç|‡§ï‡§ï‡•ç‡§∑‡§æ.*10|‡§Æ‡•à‡§ü‡•ç‡§∞‡§ø‡§ï|‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ‡§ø‡§ï'
            ],
            'te': [
                r'‡∞¨‡±Ä\.?‡∞ü‡±Ü‡∞ï‡±ç|‡∞á‡∞Ç‡∞ú‡∞®‡±Ä‡∞∞‡∞ø‡∞Ç‡∞ó‡±ç|‡∞ü‡±Ü‡∞ï‡±ç‡∞®‡∞æ‡∞≤‡∞ú‡±Ä',
                r'‡∞¨‡±Ä\.?‡∞é‡∞∏‡±ç‡∞∏‡±Ä|‡∞∏‡±à‡∞®‡±ç‡∞∏‡±ç',
                r'‡∞¨‡±Ä\.?‡∞ï‡∞æ‡∞Æ‡±ç|‡∞ï‡∞æ‡∞Æ‡∞∞‡±ç‡∞∏‡±ç',
                r'‡∞¨‡±Ä\.?‡∞è|‡∞Ü‡∞∞‡±ç‡∞ü‡±ç‡∞∏‡±ç',
                r'‡∞é‡∞Ç\.?‡∞ü‡±Ü‡∞ï‡±ç|‡∞ü‡±Ü‡∞ï‡±ç‡∞®‡∞æ‡∞≤‡∞ú‡±Ä',
                r'‡∞é‡∞Ç\.?‡∞é‡∞∏‡±ç‡∞∏‡±Ä|‡∞∏‡±à‡∞®‡±ç‡∞∏‡±ç',
                r'‡∞é‡∞Ç‡∞¨‡±Ä‡∞è|‡∞¨‡∞ø‡∞ú‡∞ø‡∞®‡±Ü‡∞∏‡±ç',
                r'‡∞°‡∞ø‡∞™‡±ç‡∞≤‡±ä‡∞Æ‡∞æ|‡∞™‡∞æ‡∞≤‡∞ø‡∞ü‡±Ü‡∞ï‡±ç‡∞®‡∞ø‡∞ï‡±ç',
                r'12‡∞µ|‡∞§‡∞∞‡∞ó‡∞§‡∞ø.*12|‡∞á‡∞Ç‡∞ü‡∞∞‡±ç‡∞Æ‡±Ä‡∞°‡∞ø‡∞Ø‡∞ü‡±ç',
                r'10‡∞µ|‡∞§‡∞∞‡∞ó‡∞§‡∞ø.*10|‡∞Æ‡±Ü‡∞ü‡±ç‡∞∞‡∞ø‡∞ï‡±ç|‡∞∏‡±Ü‡∞ï‡∞Ç‡∞°‡∞∞‡±Ä'
            ],
            'ta': [
                r'‡Æ™‡Æø\.?‡Æü‡ØÜ‡Æï‡Øç|‡Æá‡Æ©‡Øç‡Æú‡Æø‡Æ©‡Æø‡ÆØ‡Æ∞‡Æø‡Æô‡Øç|‡Æ§‡Øä‡Æ¥‡Æø‡Æ≤‡Øç‡Æ®‡ØÅ‡Æü‡Øç‡Æ™‡ÆÆ‡Øç',
                r'‡Æ™‡Æø\.?‡Æé‡Æ∏‡Øç‡Æö‡Æø|‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡ÆØ‡Æ≤‡Øç',
                r'‡Æ™‡Æø\.?‡Æï‡Ææ‡ÆÆ‡Øç|‡Æµ‡Æ£‡Æø‡Æï‡ÆÆ‡Øç',
                r'‡Æ™‡Æø\.?‡Æè|‡Æï‡Æ≤‡Øà',
                r'‡Æé‡ÆÆ‡Øç\.?‡Æü‡ØÜ‡Æï‡Øç|‡Æ§‡Øä‡Æ¥‡Æø‡Æ≤‡Øç‡Æ®‡ØÅ‡Æü‡Øç‡Æ™‡ÆÆ‡Øç',
                r'‡Æé‡ÆÆ‡Øç\.?‡Æé‡Æ∏‡Øç‡Æö‡Æø|‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡ÆØ‡Æ≤‡Øç',
                r'‡Æé‡ÆÆ‡Øç‡Æ™‡Æø‡Æè|‡Æ™‡Æø‡Æö‡Æø‡Æ©‡Æ∏‡Øç',
                r'‡Æü‡Æø‡Æ™‡Øç‡Æ≥‡ÆÆ‡Øã|‡Æ™‡Ææ‡Æ≤‡Æø‡Æü‡ØÜ‡Æï‡Øç‡Æ©‡Æø‡Æï‡Øç',
                r'12‡ÆÜ‡ÆÆ‡Øç|‡Æµ‡Æï‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ.*12|‡Æâ‡ÆØ‡Æ∞‡Øç‡Æ®‡Æø‡Æ≤‡Øà',
                r'10‡ÆÜ‡ÆÆ‡Øç|‡Æµ‡Æï‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ.*10|‡ÆÆ‡ØÜ‡Æü‡Øç‡Æ∞‡Æø‡Æï‡Øç|‡Æö‡ØÜ‡Æï‡Æ£‡Øç‡Æü‡Æ∞‡Æø'
            ],
            'bn': [
                r'‡¶¨‡¶ø\.?‡¶ü‡ßá‡¶ï|‡¶á‡¶û‡ßç‡¶ú‡¶ø‡¶®‡¶ø‡¶Ø‡¶º‡¶æ‡¶∞‡¶ø‡¶Ç|‡¶™‡ßç‡¶∞‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø',
                r'‡¶¨‡¶ø\.?‡¶è‡¶∏‡¶∏‡¶ø|‡¶¨‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶®',
                r'‡¶¨‡¶ø\.?‡¶ï‡¶Æ|‡¶¨‡¶æ‡¶£‡¶ø‡¶ú‡ßç‡¶Ø',
                r'‡¶¨‡¶ø\.?‡¶è|‡¶ï‡¶≤‡¶æ',
                r'‡¶è‡¶Æ\.?‡¶ü‡ßá‡¶ï|‡¶™‡ßç‡¶∞‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø',
                r'‡¶è‡¶Æ\.?‡¶è‡¶∏‡¶∏‡¶ø|‡¶¨‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶®',
                r'‡¶è‡¶Æ‡¶¨‡¶ø‡¶è|‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡¶æ',
                r'‡¶°‡¶ø‡¶™‡ßç‡¶≤‡ßã‡¶Æ‡¶æ|‡¶™‡¶≤‡¶ø‡¶ü‡ßá‡¶ï‡¶®‡¶ø‡¶ï',
                r'12‡¶§‡¶Æ|‡¶∂‡ßç‡¶∞‡ßá‡¶£‡ßÄ.*12|‡¶â‡¶ö‡ßç‡¶ö ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡¶ø‡¶ï',
                r'10‡¶Æ|‡¶∂‡ßç‡¶∞‡ßá‡¶£‡ßÄ.*10|‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡¶ø‡¶ï'
            ]
        }

        # Indian cities/states
        self.indian_locations = [
            'mumbai', 'delhi', 'bangalore', 'kolkata', 'chennai', 'hyderabad',
            'pune', 'ahmedabad', 'surat', 'jaipur', 'lucknow', 'kanpur',
            'nagpur', 'indore', 'thane', 'bhopal', 'visakhapatnam', 'patna',
            'vadodara', 'ghaziabad', 'ludhiana', 'agra', 'nashik', 'faridabad',
            'meerut', 'rajkot', 'kalyan', 'vasai', 'virar', 'varanasi',
            'andhra pradesh', 'maharashtra', 'tamil nadu', 'karnataka',
            'gujarat', 'rajasthan', 'west bengal', 'madhya pradesh',
            'telangana', 'kerala', 'punjab', 'haryana', 'bihar', 'odisha',
            'uttar pradesh', 'assam', 'jharkhand', 'himachal pradesh',
            'uttarakhand', 'chhattisgarh', 'goa', 'tripura', 'manipur',
            'meghalaya', 'nagaland', 'mizoram', 'arunachal pradesh', 'sikkim'
        ]
    
    def parse(self, file):
        """Main function to parse resume file with multilingual support"""
        try:
            filename = file.filename.lower()
            print(f"üìÑ Parsing file: {filename}")

            # Extract text from file
            if filename.endswith('.pdf'):
                text = self._extract_text_from_pdf(file)
            elif filename.endswith('.docx') or filename.endswith('.doc'):
                text = self._extract_text_from_docx(file)
            else:
                file.seek(0)
                text = file.read().decode('utf-8')

            print("\nüîç Extracted text preview:\n", text[:500], "\n---")

            # Process with multilingual capabilities
            parsed_data = self._parse_text_multilingual(text)
            return {
                "success": True, 
                "data": parsed_data, 
                "message": "Resume parsed successfully"
            }

        except Exception as e:
            return {
                "success": False, 
                "data": {}, 
                "message": f"Error parsing resume: {str(e)}"
            }
    
    def _parse_text_multilingual(self, text):
        """Parse extracted text with multilingual support"""
        
        # Detect the primary language of the text
        detected_language = self.text_processor.detect_language(text)
        print(f"üåê Detected language: {detected_language}")
        
        # Clean and normalize the text
        cleaned_text = self.text_processor.clean_text(text, detected_language)
        normalized_text = self.text_processor.normalize_text(cleaned_text, detected_language)
        
        # Parse different sections
        parsed_data = {
            "detected_language": detected_language,
            "name": self._extract_name_multilingual(normalized_text, detected_language),
            "email": self._extract_email(normalized_text),
            "phone": self._extract_phone(normalized_text),
            "education": self._extract_education_multilingual(normalized_text, detected_language),
            "location": self._extract_location_multilingual(normalized_text, detected_language),
            "skills": self._extract_skills_multilingual(normalized_text, detected_language)
        }
        
        # If the resume is not in English, also provide English translations
        if detected_language != 'en':
            parsed_data["translations"] = {
                "education_en": self.translation_service.translate(
                    parsed_data["education"], 'en'
                ) if parsed_data["education"] != "Not specified" else "Not specified",
                "location_en": self.translation_service.translate(
                    parsed_data["location"], 'en'
                ) if parsed_data["location"] != "Not specified" else "Not specified"
            }
        
        return parsed_data
    
    def _extract_skills_multilingual(self, text, language):
        """Extract skills with multilingual support"""
        found_skills = []
        text_lower = text.lower()
        
        # Check skills in detected language
        if language in self.skills_keywords:
            for skill in self.skills_keywords[language]:
                if re.search(r'\b' + re.escape(skill.lower()) + r'\b', text_lower):
                    found_skills.append(skill.title())
        
        # Also check English skills (common in all resumes)
        for skill in self.skills_keywords['en']:
            if re.search(r'\b' + re.escape(skill.lower()) + r'\b', text_lower):
                found_skills.append(skill.title())
        
        # Remove duplicates while preserving order
        unique_skills = list(dict.fromkeys(found_skills))
        return unique_skills[:15]  # Limit to top 15 skills
    
    def _extract_education_multilingual(self, text, language):
        """Extract education with multilingual pattern matching"""
        educations = []
        text_lower = text.lower()
        
        # Check patterns in detected language
        if language in self.education_patterns:
            for pattern in self.education_patterns[language]:
                matches = re.finditer(pattern, text_lower, re.IGNORECASE)
                for match in matches:
                    start = max(0, match.start() - 50)
                    end = min(len(text), match.end() + 50)
                    context = text[start:end].strip()
                    education_info = ' '.join(context.split())
                    if education_info and education_info not in educations:
                        educations.append(education_info[:150])
        
        # Also check English patterns (common in Indian resumes)
        for pattern in self.education_patterns['en']:
            matches = re.finditer(pattern, text_lower, re.IGNORECASE)
            for match in matches:
                start = max(0, match.start() - 50)
                end = min(len(text), match.end() + 50)
                context = text[start:end].strip()
                education_info = ' '.join(context.split())
                if education_info and education_info not in educations:
                    educations.append(education_info[:150])
        
        return educations[0] if educations else "Not specified"
    
    def _extract_location_multilingual(self, text, language):
        """Extract location with multilingual support"""
        text_lower = text.lower()
        
        # First check for known Indian locations (in English)
        for location in self.indian_locations:
            if location in text_lower:
                return location.title()
        
        # Location patterns in different languages
        location_patterns = {
            'en': [
                r'address[:\s]*([^\n]+)',
                r'location[:\s]*([^\n]+)',
                r'city[:\s]*([^\n]+)',
                r'state[:\s]*([^\n]+)',
                r'residence[:\s]*([^\n]+)'
            ],
            'hi': [
                r'‡§™‡§§‡§æ[:\s]*([^\n]+)',
                r'‡§∏‡•ç‡§•‡§æ‡§®[:\s]*([^\n]+)',
                r'‡§∂‡§π‡§∞[:\s]*([^\n]+)',
                r'‡§∞‡§æ‡§ú‡•ç‡§Ø[:\s]*([^\n]+)',
                r'‡§®‡§ø‡§µ‡§æ‡§∏[:\s]*([^\n]+)'
            ],
            'te': [
                r'‡∞ö‡∞ø‡∞∞‡±Å‡∞®‡∞æ‡∞Æ‡∞æ[:\s]*([^\n]+)',
                r'‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞Ç[:\s]*([^\n]+)',
                r'‡∞™‡∞ü‡±ç‡∞ü‡∞£‡∞Ç[:\s]*([^\n]+)',
                r'‡∞∞‡∞æ‡∞∑‡±ç‡∞ü‡±ç‡∞∞‡∞Ç[:\s]*([^\n]+)'
            ],
            'ta': [
                r'‡ÆÆ‡ØÅ‡Æï‡Æµ‡Æ∞‡Æø[:\s]*([^\n]+)',
                r'‡Æá‡Æü‡ÆÆ‡Øç[:\s]*([^\n]+)',
                r'‡Æ®‡Æï‡Æ∞‡ÆÆ‡Øç[:\s]*([^\n]+)',
                r'‡ÆÆ‡Ææ‡Æ®‡Æø‡Æ≤‡ÆÆ‡Øç[:\s]*([^\n]+)'
            ],
            'bn': [
                r'‡¶†‡¶ø‡¶ï‡¶æ‡¶®‡¶æ[:\s]*([^\n]+)',
                r'‡¶∏‡ßç‡¶•‡¶æ‡¶®[:\s]*([^\n]+)',
                r'‡¶∂‡¶π‡¶∞[:\s]*([^\n]+)',
                r'‡¶∞‡¶æ‡¶ú‡ßç‡¶Ø[:\s]*([^\n]+)'
            ]
        }
        
        # Check patterns in the detected language first
        if language in location_patterns:
            for pattern in location_patterns[language]:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    return match.group(1).strip()[:60]
        
        # Fallback to English patterns
        for pattern in location_patterns['en']:
            match = re.search(pattern, text_lower, re.IGNORECASE)
            if match:
                return match.group(1).strip()[:60]
        
        return "Not specified"
    
    def _extract_name_multilingual(self, text, language):
        """Extract name with multilingual support"""
        
        # First try spaCy if available (works best for English)
        if self.nlp and language == 'en':
            doc = self.nlp(text[:500])
            for entity in doc.ents:
                if entity.label_ == "PERSON":
                    return entity.text
        
        # Multilingual name patterns
        name_patterns = {
            'en': [r'^([A-Z][a-z]+ [A-Z][a-z]+)', r'name[:\s]*([A-Z][a-z]+ [A-Z][a-z]+)'],
            'hi': [r'^‡§®‡§æ‡§Æ[:\s]*([^‡§®\n]+)', r'^([‡§Ö-‡§π]+ [‡§Ö-‡§π]+)'],
            'te': [r'^‡∞™‡±á‡∞∞‡±Å[:\s]*([^‡∞®\n]+)', r'^([‡∞Ö-‡∞π]+ [‡∞Ö-‡∞π]+)'],
            'ta': [r'^‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç[:\s]*([^‡Æ®\n]+)', r'^([‡ÆÖ-‡Æπ]+ [‡ÆÖ-‡Æπ]+)'],
            'bn': [r'^‡¶®‡¶æ‡¶Æ[:\s]*([^‡¶®\n]+)', r'^([‡¶Ö-‡¶π]+ [‡¶Ö-‡¶π]+)']
        }
        
        # Try language-specific patterns first
        if language in name_patterns:
            for pattern in name_patterns[language]:
                for line in text.split("\n")[:8]:
                    match = re.search(pattern, line.strip(), re.IGNORECASE)
                    if match:
                        return match.group(1).strip()
        
        # Fallback: look for the first meaningful line
        for line in text.split("\n")[:5]:
            line = line.strip()
            if (3 < len(line) < 50 and 
                not any(char.isdigit() for char in line) and 
                '@' not in line and 
                ':' not in line):
                return line
        
        return "Not found"


    def _extract_text_from_pdf(self, file):
        """Extract text from PDF with OCR fallback"""
        try:
            file.seek(0)
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                extracted = page.extract_text()
                if extracted:
                    text += extracted + "\n"

            # OCR fallback if no text (only if OCR is available)
            if not text.strip() and OCR_AVAILABLE:
                print("WARNING: No text found, using OCR fallback...")
                file.seek(0)
                images = convert_from_bytes(file.read())
                for img in images:
                    text += pytesseract.image_to_string(img) + "\n"
            elif not text.strip():
                print("WARNING: No text found in PDF and OCR not available.")

            return text
        except Exception as e:
            raise Exception(f"Error reading PDF: {str(e)}")

    def _extract_text_from_docx(self, file):
        """Extract text from DOCX"""
        try:
            file.seek(0)
            doc = docx.Document(file)
            text = "\n".join([p.text for p in doc.paragraphs])
            return text
        except Exception as e:
            raise Exception(f"Error reading DOCX: {str(e)}")
    
    def _extract_email(self, text):
        """Extract email address (language-independent)"""
        matches = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text)
        return matches[0] if matches else "Not found"

    def _extract_phone(self, text):
        """Extract phone number (language-independent)"""
        patterns = [
            r'\+91[-\s]?\d{10}',
            r'\d{10}',
            r'\d{3}[-\s]?\d{3}[-\s]?\d{4}'
        ]
        for pattern in patterns:
            matches = re.findall(pattern, text)
            if matches:
                return matches[0]
        return "Not found"
