import PyPDF2
import docx
import re
from io import BytesIO
from .indic_text_processor import IndicTextProcessor
from .translation_service import TranslationService

# Optional dependencies for better functionality
try:
    from pdf2image import convert_from_bytes
    import pytesseract
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False
    print("WARNING: OCR dependencies not available. Install pillow and pytesseract for better PDF parsing.")

try:
    import spacy
    SPACY_AVAILABLE = True
except ImportError:
    SPACY_AVAILABLE = False
    print("WARNING: spaCy not available. Name extraction will use fallback method.")


class ResumeParser:
    def __init__(self):
        # Initialize multilingual text processing
        self.text_processor = IndicTextProcessor()
        self.translation_service = TranslationService()
        
        # Load spaCy model if available
        self.nlp = None
        if SPACY_AVAILABLE: 
            try:
                self.nlp = spacy.load("en_core_web_sm")
            except OSError:
                print("WARNING: spaCy model 'en_core_web_sm' not found.")
                print("    For better name extraction, install with: python -m spacy download en_core_web_sm")
                self.nlp = None

        # Multilingual skills dictionary (extendable)
        self.skills_keywords = {
            'en': [
                'python', 'java', 'javascript', 'html', 'css', 'react', 'angular', 'vue',
                'node.js', 'express', 'django', 'flask', 'spring', 'sql', 'mysql', 'postgresql',
                'mongodb', 'git', 'docker', 'kubernetes', 'aws', 'azure', 'gcp', 'linux',
                'windows', 'photoshop', 'illustrator', 'figma', 'sketch', 'autocad', 'solidworks',
                'excel', 'powerpoint', 'word', 'tableau', 'power bi', 'r', 'matlab', 'tensorflow',
                'pytorch', 'machine learning', 'deep learning', 'data science', 'analytics',
                'marketing', 'seo', 'content writing', 'social media', 'communication',
                'leadership', 'project management', 'agile', 'scrum', 'teamwork', 'problem solving'
            ],
            'hi': [
                'рдкрд╛рдпрдерди', 'рдЬрд╛рд╡рд╛', 'рдкреНрд░реЛрдЧреНрд░рд╛рдорд┐рдВрдЧ', 'рдХрдВрдкреНрдпреВрдЯрд░', 'рд╕реЙрдлреНрдЯрд╡реЗрдпрд░', 'рдбреЗрдЯрд╛',
                'рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ', 'рдХреГрддреНрд░рд┐рдо рдмреБрджреНрдзрд┐рдорддреНрддрд╛', 'рд╡реЗрдм рдбреЗрд╡рд▓рдкрдореЗрдВрдЯ', 'рдореЛрдмрд╛рдЗрд▓',
                'рдбрд┐рдЬрд╛рдЗрди', 'рдорд╛рд░реНрдХреЗрдЯрд┐рдВрдЧ', 'рдмрд┐рдХреНрд░реА', 'рдкреНрд░рдмрдВрдзрди', 'рдиреЗрддреГрддреНрд╡', 'рд╕рдВрдЪрд╛рд░',
                'рдЯреАрдорд╡рд░реНрдХ', 'рд╕рдорд╕реНрдпрд╛ рд╕рдорд╛рдзрд╛рди', 'рд╡рд┐рд╢реНрд▓реЗрд╖рдг', 'рд░рд┐рдкреЛрд░реНрдЯрд┐рдВрдЧ'
            ],
            'te': [
                'р░кр▒Нр░░р▒Лр░Чр▒Нр░░р░╛р░ор░┐р░Вр░Чр▒Н', 'р░Хр░Вр░кр▒Нр░пр▒Вр░Яр░░р▒Н', 'р░╕р░╛р░лр▒Нр░Яр▒НтАМр░╡р▒Зр░░р▒Н', 'р░бр▒Зр░Яр░╛', 'р░╡р▒Жр░мр▒Н р░бр▒Жр░╡р░▓р░кр▒НтАМр░ор▒Жр░Вр░Яр▒Н',
                'р░ор▒Кр░мр▒Ир░▓р▒Н', 'р░бр░┐р░Ьр▒Ир░ир▒Н', 'р░ор░╛р░░р▒Нр░Хр▒Жр░Яр░┐р░Вр░Чр▒Н', 'р░╕р▒Зр░▓р▒Нр░╕р▒Н', 'р░ор▒Зр░ир▒Зр░Ьр▒НтАМр░ор▒Жр░Вр░Яр▒Н',
                'р░▓р▒Ар░бр░░р▒НтАМр░╖р░┐р░кр▒Н', 'р░Хр░ор▒Нр░пр▒Вр░ир░┐р░Хр▒Зр░╖р░ир▒Н', 'р░Яр▒Ар░ор▒НтАМр░╡р░░р▒Нр░Хр▒Н', 'р░╕р░ор░╕р▒Нр░п р░кр░░р░┐р░╖р▒Нр░Хр░╛р░░р░В'
            ],
            'ta': [
                'роиро┐ро░ро▓ро╛роХрпНроХроорпН', 'роХрогро┐ройро┐', 'роорпЖройрпНрокрпКро░рпБро│рпН', 'родро░ро╡рпБ', 'ро╡ро▓рпИ роорпЗроорпНрокро╛роЯрпБ',
                'роорпКрокрпИро▓рпН', 'ро╡роЯро┐ро╡роорпИрокрпНрокрпБ', 'роЪроирпНродрпИрокрпНрокроЯрпБродрпНродро▓рпН', 'ро╡ро┐ро▒рпНрокройрпИ', 'роорпЗро▓ро╛рогрпНроорпИ',
                'родро▓рпИроорпИродрпНродрпБро╡роорпН', 'родроХро╡ро▓рпНродрпКроЯро░рпНрокрпБ', 'роХрпБро┤рпБ ро╡рпЗро▓рпИ', 'роЪро┐роХрпНроХро▓рпН родрпАро░рпНро╡рпБ'
            ],
            'bn': [
                'ржкрзНрж░рзЛржЧрзНрж░рж╛ржорж┐ржВ', 'ржХржорзНржкрж┐ржЙржЯрж╛рж░', 'рж╕ржлржЯржУржпрж╝рзНржпрж╛рж░', 'ржбрж╛ржЯрж╛', 'ржУржпрж╝рзЗржм ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯ',
                'ржорзЛржмрж╛ржЗрж▓', 'ржбрж┐ржЬрж╛ржЗржи', 'ржорж╛рж░рзНржХрзЗржЯрж┐ржВ', 'рж╕рзЗрж▓рж╕', 'ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ',
                'рж▓рж┐ржбрж╛рж░рж╢рж┐ржк', 'ржХржорж┐ржЙржирж┐ржХрзЗрж╢ржи', 'ржЯрж┐ржоржУржпрж╝рж╛рж░рзНржХ', 'рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржи'
            ]
        }

        # Education patterns (multilingual)
        self.education_patterns = {
            'en': [
                r'b\.?tech|bachelor.*technology|engineering',
                r'b\.?sc|bachelor.*science',
                r'b\.?com|bachelor.*commerce',
                r'b\.?a|bachelor.*arts',
                r'm\.?tech|master.*technology',
                r'm\.?sc|master.*science',
                r'mba|master.*business',
                r'diploma|polytechnic',
                r'12th|class.*12|higher.*secondary|intermediate',
                r'10th|class.*10|matriculation|secondary'
            ],
            'hi': [
                r'рдмреА\.?рдЯреЗрдХ|рдЗрдВрдЬреАрдирд┐рдпрд░рд┐рдВрдЧ|рддрдХрдиреАрдХреА',
                r'рдмреА\.?рдПрд╕рд╕реА|рд╡рд┐рдЬреНрдЮрд╛рди',
                r'рдмреА\.?рдХреЙрдо|рд╡рд╛рдгрд┐рдЬреНрдп',
                r'рдмреА\.?рдП|рдХрд▓рд╛',
                r'рдПрдо\.?рдЯреЗрдХ|рдкреНрд░реМрджреНрдпреЛрдЧрд┐рдХреА',
                r'рдПрдо\.?рдПрд╕рд╕реА|рд╡рд┐рдЬреНрдЮрд╛рди',
                r'рдПрдордмреАрдП|рдмрд┐рдЬрдиреЗрд╕|рд╡реНрдпрд╛рдкрд╛рд░',
                r'рдбрд┐рдкреНрд▓реЛрдорд╛|рдкреЙрд▓рд┐рдЯреЗрдХреНрдирд┐рдХ',
                r'12рд╡реАрдВ|рдХрдХреНрд╖рд╛.*12|рдЙрдЪреНрдЪ рдорд╛рдзреНрдпрдорд┐рдХ|рдЗрдВрдЯрд░рдореАрдбрд┐рдПрдЯ',
                r'10рд╡реАрдВ|рдХрдХреНрд╖рд╛.*10|рдореИрдЯреНрд░рд┐рдХ|рдорд╛рдзреНрдпрдорд┐рдХ'
            ],
            'te': [
                r'р░мр▒А\.?р░Яр▒Жр░Хр▒Н|р░Зр░Вр░Ьр░ир▒Ар░░р░┐р░Вр░Чр▒Н|р░Яр▒Жр░Хр▒Нр░ир░╛р░▓р░Ьр▒А',
                r'р░мр▒А\.?р░Ор░╕р▒Нр░╕р▒А|р░╕р▒Ир░ир▒Нр░╕р▒Н',
                r'р░мр▒А\.?р░Хр░╛р░ор▒Н|р░Хр░╛р░ор░░р▒Нр░╕р▒Н',
                r'р░мр▒А\.?р░П|р░Жр░░р▒Нр░Яр▒Нр░╕р▒Н',
                r'р░Ор░В\.?р░Яр▒Жр░Хр▒Н|р░Яр▒Жр░Хр▒Нр░ир░╛р░▓р░Ьр▒А',
                r'р░Ор░В\.?р░Ор░╕р▒Нр░╕р▒А|р░╕р▒Ир░ир▒Нр░╕р▒Н',
                r'р░Ор░Вр░мр▒Ар░П|р░мр░┐р░Ьр░┐р░ир▒Жр░╕р▒Н',
                r'р░бр░┐р░кр▒Нр░▓р▒Кр░ор░╛|р░кр░╛р░▓р░┐р░Яр▒Жр░Хр▒Нр░ир░┐р░Хр▒Н',
                r'12р░╡|р░др░░р░Чр░др░┐.*12|р░Зр░Вр░Яр░░р▒Нр░ор▒Ар░бр░┐р░пр░Яр▒Н',
                r'10р░╡|р░др░░р░Чр░др░┐.*10|р░ор▒Жр░Яр▒Нр░░р░┐р░Хр▒Н|р░╕р▒Жр░Хр░Вр░бр░░р▒А'
            ],
            'ta': [
                r'рокро┐\.?роЯрпЖроХрпН|роЗройрпНроЬро┐ройро┐ропро░ро┐роЩрпН|родрпКро┤ро┐ро▓рпНроирпБроЯрпНрокроорпН',
                r'рокро┐\.?роОро╕рпНроЪро┐|роЕро▒ро┐ро╡ро┐ропро▓рпН',
                r'рокро┐\.?роХро╛роорпН|ро╡рогро┐роХроорпН',
                r'рокро┐\.?роП|роХро▓рпИ',
                r'роОроорпН\.?роЯрпЖроХрпН|родрпКро┤ро┐ро▓рпНроирпБроЯрпНрокроорпН',
                r'роОроорпН\.?роОро╕рпНроЪро┐|роЕро▒ро┐ро╡ро┐ропро▓рпН',
                r'роОроорпНрокро┐роП|рокро┐роЪро┐ройро╕рпН',
                r'роЯро┐рокрпНро│роорпЛ|рокро╛ро▓ро┐роЯрпЖроХрпНройро┐роХрпН',
                r'12роЖроорпН|ро╡роХрпБрокрпНрокрпБ.*12|роЙропро░рпНроиро┐ро▓рпИ',
                r'10роЖроорпН|ро╡роХрпБрокрпНрокрпБ.*10|роорпЖроЯрпНро░ро┐роХрпН|роЪрпЖроХрогрпНроЯро░ро┐'
            ],
            'bn': [
                r'ржмрж┐\.?ржЯрзЗржХ|ржЗржЮрзНржЬрж┐ржирж┐ржпрж╝рж╛рж░рж┐ржВ|ржкрзНрж░ржпрзБржХрзНрждрж┐',
                r'ржмрж┐\.?ржПрж╕рж╕рж┐|ржмрж┐ржЬрзНржЮрж╛ржи',
                r'ржмрж┐\.?ржХржо|ржмрж╛ржгрж┐ржЬрзНржп',
                r'ржмрж┐\.?ржП|ржХрж▓рж╛',
                r'ржПржо\.?ржЯрзЗржХ|ржкрзНрж░ржпрзБржХрзНрждрж┐',
                r'ржПржо\.?ржПрж╕рж╕рж┐|ржмрж┐ржЬрзНржЮрж╛ржи',
                r'ржПржоржмрж┐ржП|ржмрзНржпржмрж╕рж╛',
                r'ржбрж┐ржкрзНрж▓рзЛржорж╛|ржкрж▓рж┐ржЯрзЗржХржирж┐ржХ',
                r'12рждржо|рж╢рзНрж░рзЗржгрзА.*12|ржЙржЪрзНржЪ ржорж╛ржзрзНржпржорж┐ржХ',
                r'10ржо|рж╢рзНрж░рзЗржгрзА.*10|ржорж╛ржзрзНржпржорж┐ржХ'
            ]
        }

        # Indian cities/states
        self.indian_locations = [
            'mumbai', 'delhi', 'bangalore', 'kolkata', 'chennai', 'hyderabad',
            'pune', 'ahmedabad', 'surat', 'jaipur', 'lucknow', 'kanpur',
            'nagpur', 'indore', 'thane', 'bhopal', 'visakhapatnam', 'patna',
            'vadodara', 'ghaziabad', 'ludhiana', 'agra', 'nashik', 'faridabad',
            'meerut', 'rajkot', 'kalyan', 'vasai', 'virar', 'varanasi',
            'andhra pradesh', 'maharashtra', 'tamil nadu', 'karnataka',
            'gujarat', 'rajasthan', 'west bengal', 'madhya pradesh',
            'telangana', 'kerala', 'punjab', 'haryana', 'bihar', 'odisha',
            'uttar pradesh', 'assam', 'jharkhand', 'himachal pradesh',
            'uttarakhand', 'chhattisgarh', 'goa', 'tripura', 'manipur',
            'meghalaya', 'nagaland', 'mizoram', 'arunachal pradesh', 'sikkim'
        ]
    
    def parse(self, file):
        """Main function to parse resume file with multilingual support"""
        try:
            filename = file.filename.lower()
            print(f"ЁЯУД Parsing file: {filename}")

            # Extract text from file
            if filename.endswith('.pdf'):
                text = self._extract_text_from_pdf(file)
            elif filename.endswith('.docx') or filename.endswith('.doc'):
                text = self._extract_text_from_docx(file)
            else:
                file.seek(0)
                text = file.read().decode('utf-8')

            print("\nЁЯФН Extracted text preview:\n", text[:500], "\n---")

            # Process with multilingual capabilities
            parsed_data = self._parse_text_multilingual(text)
            return {
                "success": True, 
                "data": parsed_data, 
                "message": "Resume parsed successfully"
            }

        except Exception as e:
            return {
                "success": False, 
                "data": {}, 
                "message": f"Error parsing resume: {str(e)}"
            }
    
    def _parse_text_multilingual(self, text):
        """Parse extracted text with multilingual support"""
        
        # Detect the primary language of the text
        detected_language = self.text_processor.detect_language(text)
        print(f"ЁЯМР Detected language: {detected_language}")
        
        # Clean and normalize the text
        cleaned_text = self.text_processor.clean_text(text, detected_language)
        normalized_text = self.text_processor.normalize_text(cleaned_text, detected_language)
        
        # Parse different sections
        parsed_data = {
            "detected_language": detected_language,
            "name": self._extract_name_multilingual(normalized_text, detected_language),
            "email": self._extract_email(normalized_text),
            "phone": self._extract_phone(normalized_text),
            "education": self._extract_education_multilingual(normalized_text, detected_language),
            "location": self._extract_location_multilingual(normalized_text, detected_language),
            "skills": self._extract_skills_multilingual(normalized_text, detected_language)
        }
        
        # If the resume is not in English, also provide English translations
        if detected_language != 'en':
            parsed_data["translations"] = {
                "education_en": self.translation_service.translate(
                    parsed_data["education"], 'en'
                ) if parsed_data["education"] != "Not specified" else "Not specified",
                "location_en": self.translation_service.translate(
                    parsed_data["location"], 'en'
                ) if parsed_data["location"] != "Not specified" else "Not specified"
            }
        
        return parsed_data
    
    def _extract_skills_multilingual(self, text, language):
        """Extract skills with multilingual support"""
        found_skills = []
        text_lower = text.lower()
        
        # Check skills in detected language
        if language in self.skills_keywords:
            for skill in self.skills_keywords[language]:
                if re.search(r'\b' + re.escape(skill.lower()) + r'\b', text_lower):
                    found_skills.append(skill.title())
        
        # Also check English skills (common in all resumes)
        for skill in self.skills_keywords['en']:
            if re.search(r'\b' + re.escape(skill.lower()) + r'\b', text_lower):
                found_skills.append(skill.title())
        
        # Remove duplicates while preserving order
        unique_skills = list(dict.fromkeys(found_skills))
        return unique_skills[:15]  # Limit to top 15 skills
    
    def _extract_education_multilingual(self, text, language):
        """Extract education with multilingual pattern matching"""
        educations = []
        text_lower = text.lower()
        
        # Check patterns in detected language
        if language in self.education_patterns:
            for pattern in self.education_patterns[language]:
                matches = re.finditer(pattern, text_lower, re.IGNORECASE)
                for match in matches:
                    start = max(0, match.start() - 50)
                    end = min(len(text), match.end() + 50)
                    context = text[start:end].strip()
                    education_info = ' '.join(context.split())
                    if education_info and education_info not in educations:
                        educations.append(education_info[:150])
        
        # Also check English patterns (common in Indian resumes)
        for pattern in self.education_patterns['en']:
            matches = re.finditer(pattern, text_lower, re.IGNORECASE)
            for match in matches:
                start = max(0, match.start() - 50)
                end = min(len(text), match.end() + 50)
                context = text[start:end].strip()
                education_info = ' '.join(context.split())
                if education_info and education_info not in educations:
                    educations.append(education_info[:150])
        
        return educations[0] if educations else "Not specified"
    
    def _extract_location_multilingual(self, text, language):
        """Extract location with multilingual support"""
        text_lower = text.lower()
        
        # First check for known Indian locations (in English)
        for location in self.indian_locations:
            if location in text_lower:
                return location.title()
        
        # Location patterns in different languages
        location_patterns = {
            'en': [
                r'address[:\s]*([^\n]+)',
                r'location[:\s]*([^\n]+)',
                r'city[:\s]*([^\n]+)',
                r'state[:\s]*([^\n]+)',
                r'residence[:\s]*([^\n]+)'
            ],
            'hi': [
                r'рдкрддрд╛[:\s]*([^\n]+)',
                r'рд╕реНрдерд╛рди[:\s]*([^\n]+)',
                r'рд╢рд╣рд░[:\s]*([^\n]+)',
                r'рд░рд╛рдЬреНрдп[:\s]*([^\n]+)',
                r'рдирд┐рд╡рд╛рд╕[:\s]*([^\n]+)'
            ],
            'te': [
                r'р░Ър░┐р░░р▒Бр░ир░╛р░ор░╛[:\s]*([^\n]+)',
                r'р░╕р▒Нр░ер░╛р░ир░В[:\s]*([^\n]+)',
                r'р░кр░Яр▒Нр░Яр░гр░В[:\s]*([^\n]+)',
                r'р░░р░╛р░╖р▒Нр░Яр▒Нр░░р░В[:\s]*([^\n]+)'
            ],
            'ta': [
                r'роорпБроХро╡ро░ро┐[:\s]*([^\n]+)',
                r'роЗроЯроорпН[:\s]*([^\n]+)',
                r'роироХро░роорпН[:\s]*([^\n]+)',
                r'рооро╛роиро┐ро▓роорпН[:\s]*([^\n]+)'
            ],
            'bn': [
                r'ржарж┐ржХрж╛ржирж╛[:\s]*([^\n]+)',
                r'рж╕рзНржерж╛ржи[:\s]*([^\n]+)',
                r'рж╢рж╣рж░[:\s]*([^\n]+)',
                r'рж░рж╛ржЬрзНржп[:\s]*([^\n]+)'
            ]
        }
        
        # Check patterns in the detected language first
        if language in location_patterns:
            for pattern in location_patterns[language]:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    return match.group(1).strip()[:60]
        
        # Fallback to English patterns
        for pattern in location_patterns['en']:
            match = re.search(pattern, text_lower, re.IGNORECASE)
            if match:
                return match.group(1).strip()[:60]
        
        return "Not specified"
    
    def _extract_name_multilingual(self, text, language):
        """Extract name with multilingual support"""
        
        # First try spaCy if available (works best for English)
        if self.nlp and language == 'en':
            doc = self.nlp(text[:500])
            for entity in doc.ents:
                if entity.label_ == "PERSON":
                    return entity.text
        
        # Multilingual name patterns
        name_patterns = {
            'en': [r'^([A-Z][a-z]+ [A-Z][a-z]+)', r'name[:\s]*([A-Z][a-z]+ [A-Z][a-z]+)'],
            'hi': [r'^рдирд╛рдо[:\s]*([^рди\n]+)', r'^([рдЕ-рд╣]+ [рдЕ-рд╣]+)'],
            'te': [r'^р░кр▒Зр░░р▒Б[:\s]*([^р░и\n]+)', r'^([р░Е-р░╣]+ [р░Е-р░╣]+)'],
            'ta': [r'^рокрпЖропро░рпН[:\s]*([^рои\n]+)', r'^([роЕ-ро╣]+ [роЕ-ро╣]+)'],
            'bn': [r'^ржирж╛ржо[:\s]*([^ржи\n]+)', r'^([ржЕ-рж╣]+ [ржЕ-рж╣]+)']
        }
        
        # Try language-specific patterns first
        if language in name_patterns:
            for pattern in name_patterns[language]:
                for line in text.split("\n")[:8]:
                    match = re.search(pattern, line.strip(), re.IGNORECASE)
                    if match:
                        return match.group(1).strip()
        
        # Fallback: look for the first meaningful line
        for line in text.split("\n")[:5]:
            line = line.strip()
            if (3 < len(line) < 50 and 
                not any(char.isdigit() for char in line) and 
                '@' not in line and 
                ':' not in line):
                return line
        
        return "Not found"


    def _extract_text_from_pdf(self, file):
        """Extract text from PDF with OCR fallback"""
        try:
            file.seek(0)
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                extracted = page.extract_text()
                if extracted:
                    text += extracted + "\n"

            # OCR fallback if no text (only if OCR is available)
            if not text.strip() and OCR_AVAILABLE:
                print("WARNING: No text found, using OCR fallback...")
                file.seek(0)
                images = convert_from_bytes(file.read())
                for img in images:
                    text += pytesseract.image_to_string(img) + "\n"
            elif not text.strip():
                print("WARNING: No text found in PDF and OCR not available.")

            return text
        except Exception as e:
            raise Exception(f"Error reading PDF: {str(e)}")

    def _extract_text_from_docx(self, file):
        """Extract text from DOCX"""
        try:
            file.seek(0)
            doc = docx.Document(file)
            text = "\n".join([p.text for p in doc.paragraphs])
            return text
        except Exception as e:
            raise Exception(f"Error reading DOCX: {str(e)}")
    
    def _extract_email(self, text):
        """Extract email address (language-independent)"""
        matches = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text)
        return matches[0] if matches else "Not found"

    def _extract_phone(self, text):
        """Extract phone number (language-independent)"""
        patterns = [
            r'\+91[-\s]?\d{10}',
            r'\d{10}',
            r'\d{3}[-\s]?\d{3}[-\s]?\d{4}'
        ]
        for pattern in patterns:
            matches = re.findall(pattern, text)
            if matches:
                return matches[0]
        return "Not found"
